{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ebc0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import parse\n",
    "import builtins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631adc97",
   "metadata": {},
   "source": [
    "#### takes .cupt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e754ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### change the file name and path accordingly\n",
    "data_file = builtins.open(\"../data/dev_cause.cupt\", \"r\", encoding=\"utf-8\")\n",
    "# data_file = open(\"data/dev.cupt\", \"r\", encoding=\"utf-8\") \n",
    "data = data_file.read()\n",
    "list_tokenlist = parse(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e10867",
   "metadata": {},
   "outputs": [],
   "source": [
    "va_ending = ['वा', 'वाती', 'वाता', 'वाते', 'वाया', 'वाई', 'वायी', 'वाये', 'वाए', 'वाना', 'वाने', 'वानी']\n",
    "non_verb = ['हैं', 'है', 'चाह', 'चुक','था','हो', 'रह', 'सक', 'वाला', 'चुका', 'चाहिये', 'चाहिए', 'पा', 'पड़','पड', 'पड़','पड़ेगा', 'चहिए']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b35417",
   "metadata": {},
   "source": [
    "#### following functions:\n",
    "1. assign_token_id : assigns sentence id to each token for mapping\n",
    "2. get_parse_iteration: if parseme:mwe column is already tagged this function returns the indexical id\n",
    "3. tag_lvc: annotates LVCs\n",
    "4. tag_mvc: annotates MVCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d860cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_token_id(sentences):\n",
    "    id_list = []\n",
    "    for sentence in sentences:\n",
    "#         print(sentence)\n",
    "        for token in sentence:\n",
    "            token['new_id'] = sentence.metadata['source_sent_id']\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfc1803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parse_iteration(sentences):\n",
    "    parse_dict = {}\n",
    "    vmwe_iter = {}\n",
    "    for sentence in sentences:\n",
    "        for token in sentence:\n",
    "            if token['new_id'] not in parse_dict:\n",
    "                parse_dict[token['new_id']] = [token['parseme:mwe']]\n",
    "            else:\n",
    "                parse_dict[token['new_id']].append(token['parseme:mwe'])\n",
    "\n",
    "    for k,v in parse_dict.items():\n",
    "        l=[int(x) for x in v if isinstance(x,int) or x.isdigit()]\n",
    "        vmwe_iter[k] = max(l) if l else 0\n",
    "#     print(lvc_iter)\n",
    "    return vmwe_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd544946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_lvc(sentences):\n",
    "    prev_id = ''\n",
    "    prev_parse = 0\n",
    "    for sentence in sentences:\n",
    "        for token in sentence:\n",
    "            if token['xpos'] == 'VM':\n",
    "                next_id = token['new_id']  ### initializing a new variable\n",
    "                for nt in sentence:  ### nt-> nount_token\n",
    "                    if (nt['head'] == token['id']) and (nt['xpos'] == 'NN') and nt['deprel'] == 'compound'and (nt['parseme:mwe']=='*'):\n",
    "                            ### Causative LVCs  -- only va causative\n",
    "                        if token['form'] !=None and token['feats'] !=None  and any(token['form'].endswith(v) for v in va_ending):\n",
    "#                         if token['form'] !=None and token['feats'] !=None  and 'Cause' in token['feats']: ## tags all causatives\n",
    "\n",
    "                            ### checks for if the token belongs to same sentence if yes then increment else start at 1\n",
    "\n",
    "                            if prev_id == next_id:\n",
    "                                if token['parseme:mwe'] == '*':\n",
    "                                    token['parseme:mwe'] = str(int(prev_parse)+1)\n",
    "                                    nt['parseme:mwe'] = str(token['parseme:mwe'])+':LVC.cause'\n",
    "                                else:\n",
    "                                    token['parseme:mwe'] = str(int(prev_parse)+1) + ';'+ token['parseme:mwe']\n",
    "                                    nt['parseme:mwe'] = str(token['parseme:mwe'])+':LVC.cause'\n",
    "                                prev_id = next_id\n",
    "                                prev_parse = int(token['parseme:mwe'])\n",
    "                                print(prev_parse)\n",
    "                            \n",
    "                            else:\n",
    "                                token['parseme:mwe'] = 1\n",
    "                                nt['parseme:mwe'] = str(token['parseme:mwe'])+':LVC.cause'\n",
    "                                prev_parse = int(token['parseme:mwe'])\n",
    "                                prev_id = next_id\n",
    "                                \n",
    "                            prev_parse = int(token['parseme:mwe'])\n",
    "                            print(prev_parse)\n",
    "                            prev_id = next_id\n",
    "\n",
    "                            ### non-causative LVCs\n",
    "                        else:\n",
    "                                \n",
    "                            if prev_id == next_id:\n",
    "                                if token['parseme:mwe'] == '*':\n",
    "                                    token['parseme:mwe'] = str(int(prev_parse)+1)\n",
    "                                    nt['parseme:mwe'] = str(token['parseme:mwe'])+':LVC.full'\n",
    "                                else:\n",
    "                                    token['parseme:mwe'] = str(int(prev_parse)+1) + ','+ token['parseme:mwe']\n",
    "                                    nt['parseme:mwe'] = str(token['parseme:mwe'])+':LVC.full'\n",
    "                                prev_id = next_id\n",
    "                                prev_parse = int(token['parseme:mwe'])\n",
    "                                print(prev_parse)\n",
    "                            else:\n",
    "                                token['parseme:mwe'] = 1\n",
    "                                nt['parseme:mwe'] = str(token['parseme:mwe'])+':LVC.full'\n",
    "                                prev_parse = int(token['parseme:mwe'])\n",
    "                                prev_id = next_id\n",
    "                        prev_parse= int(token['parseme:mwe'])\n",
    "                        print(prev_parse)\n",
    "                        print(nt, nt['parseme:mwe'], token,token['parseme:mwe'])\n",
    "                        # lvc_auto.append((nt['form'], token['form']))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377be69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sent_list = assign_token_id(list_tokenlist)\n",
    "sentence_lvc = tag_lvc(new_sent_list)\n",
    "# for sentence in sentence_lvc:\n",
    "#     print(sentence.serialize()) ## prints sentences in cupt format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e610ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_mvc(sentences, lvc_iter_id):\n",
    "    prev_id = ''\n",
    "    prev_parse = 0\n",
    "    for sentence in sentences:\n",
    "        for token in sentence:\n",
    "            if token['xpos']=='VM' and (token['feats']!= None) and 'Aspect' not in token['feats']:\n",
    "                for vt in sentence: ### vt -> verb token\n",
    "                    if (vt is not None) and (vt['xpos'] == 'VAUX') and (vt['lemma'] not in non_verb) \\\n",
    "                        and (vt['head'] == token['id']) and (vt['id']-token['id']==1) and vt['feats']!=None:\n",
    "                        next_id = token['new_id']\n",
    "                        if 'MVC' in str(token['parseme:mwe']):\n",
    "                            continue\n",
    "                        else:\n",
    "                            for sent_id, iter_no in lvc_iter_id.items():\n",
    "                                if (vt['new_id'] == sent_id):\n",
    "                                    if prev_id == next_id:\n",
    "                                        vt['parseme:mwe'] = prev_parse+1\n",
    "                                        if token['parseme:mwe'] == '*':\n",
    "                                            token['parseme:mwe'] = str(vt['parseme:mwe']) + ':MVC.full'\n",
    "                                        else:\n",
    "                                            token['parseme:mwe'] = str(token['parseme:mwe'])+';'+str(vt['parseme:mwe'])+':MVC.full'\n",
    "                                    else:\n",
    "                                        vt['parseme:mwe'] = iter_no+1\n",
    "                                        if token['parseme:mwe'] == '*':\n",
    "                                            token['parseme:mwe'] = str(vt['parseme:mwe']) + ':MVC'\n",
    "                                        else:\n",
    "                                            token['parseme:mwe'] = str(token['parseme:mwe'])+';'+str(vt['parseme:mwe'])+':MVC'\n",
    "                                    prev_id = next_id\n",
    "                                    prev_parse = vt['parseme:mwe']\n",
    "            del token['new_id'] ### removes the new_id column\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb46d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "lvc_iter_id = get_parse_iteration(sentence_lvc)\n",
    "sentence_mvc = tag_mvc(sentence_lvc, lvc_iter_id)\n",
    "\n",
    "### change file name and path accordingly and save file in cupt format\n",
    "outfile = builtins.open('../data/dev_vmwe.cupt', 'w', encoding='utf-8')\n",
    "\n",
    "for sentence in sentence_mvc:\n",
    "#     print(sentence.serialize())\n",
    "    outfile.writelines(sentence.serialize() + '\\n')\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf73ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
