{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bdd4b55",
   "metadata": {},
   "source": [
    "#### takes the cupt file and gives the list of tokens for all the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2ebc0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import parse\n",
    "import builtins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5c04142",
   "metadata": {},
   "outputs": [],
   "source": [
    "### change the file name and path accordingly\n",
    "data_file = builtins.open(\"../data/dev.cupt\", \"r\", encoding=\"utf-8\") \n",
    "data = data_file.read()\n",
    "list_tokenlist = parse(data)\n",
    "# print(list_tokenlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f282f1a",
   "metadata": {},
   "source": [
    "#### list of :\n",
    "1. /-va/ endings\n",
    "2. /-a/ endings\n",
    "3. excluded verbs: that do not form /a/ causatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70e10867",
   "metadata": {},
   "outputs": [],
   "source": [
    "va_ending = ['वा', 'वाती', 'वाता', 'वाते', 'वाया', 'वाई', 'वायी', 'वाये', 'वाए', 'वाना', 'वाने', 'वानी']\n",
    "aa_ending = ['ाती', 'ाता', 'ाते', 'ाया', 'ाई', 'ायी', 'ाये', 'ाए', 'ाना', 'ाने', 'ानी']\n",
    "excluded_verbs = ['बत','पा', 'आ','जा','बता','ला','जता','छा','लुभ','बुल','दोहरा','लुभा','बुला','खटखटा','लहरा','खा']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b35417",
   "metadata": {},
   "source": [
    "#### the function add_cause:\n",
    "1. filters verbs using their xpos\n",
    "2. checks the ending of the verbs\n",
    "3. adds the morph cause annotation to the verbs found in step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaf77d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cause(sentences):\n",
    "    for sentence in sentences:\n",
    "        for token in sentence:\n",
    "            if token['xpos'] == 'VM' or token['xpos']=='VAUX':\n",
    "                if any(token['form'].endswith(aa) for aa in aa_ending) and (token['lemma'].endswith('ा')) \\\n",
    "                and not (token['lemma'].endswith('ना')) and (token['lemma'] not in excluded_verbs):\n",
    "                    if 'Cause' not in token['feats']:\n",
    "                        token['feats']['Cause'] = 'Yes'\n",
    "                elif any(token['form'].endswith(va) for va in va_ending):\n",
    "                    if 'Cause' not in token['feats']:\n",
    "                        token['feats']['Cause'] = 'Yes'\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009c033f",
   "metadata": {},
   "source": [
    "#### save annotated sentences to a new cupt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a3dc0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_cause = add_cause(list_tokenlist)\n",
    "\n",
    "### change file name and path\n",
    "outfile = open('../data/dev_cause.cupt', 'w', encoding='utf-8')\n",
    "\n",
    "for sentence in sent_cause:\n",
    "#     print(sentence.serialize())   ## prints annotated data in cupt format\n",
    "    outfile.writelines(sentence.serialize() + '\\n')\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f2a69e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
